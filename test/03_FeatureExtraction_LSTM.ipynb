{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda:2\n"
     ]
    }
   ],
   "source": [
    "from chosen_gpu import get_freer_gpu\n",
    "device = torch.device(get_freer_gpu()) \n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par = \"par16\"\n",
    "# file = \"16-Rom_1_2021-04-09-10.33.02\"\n",
    "# task = \"_visual\"\n",
    "\n",
    "# # path = '../data/np/{par}/{file}{task}.npy'.format(par=par,file=file, task=task)\n",
    "\n",
    "# X = np.load('../data/np/round2/{par}/{file}{task}_X.npy'.format(par=par,file=file, task=task))\n",
    "# y = np.load('../data/np/round2/{par}/{file}{task}_y.npy'.format(par=par,file=file, task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = \"par1_v2\"\n",
    "file = \"1-Chaichan_1_2021-04-07-06.24.14\"\n",
    "task = \"_visual\"\n",
    "model_name = \"cnn\"\n",
    "drift = \"no_drift\"\n",
    "# path = '../data/np/{par}/{file}{task}.npy'.format(par=par,file=file, task=task)\n",
    "\n",
    "X = np.load('../data/np/round2/{par}/{drift}/{file}{task}_X.npy'.format(par=par,drift = drift,file=file, task=task), allow_pickle=True)\n",
    "y = np.load('../data/np/round2/{par}/{drift}/{file}{task}_y.npy'.format(par=par,drift = drift,file=file, task=task), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Check shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16, 49)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# [# stim, # electrod, # datapoint]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Plot to see wheter eegs have drift or not\n",
    "# data = X.reshape(-1,16)\n",
    "# print(data.shape)\n",
    "# fig, ax = plt.subplots(16,1,figsize=(200,100),sharex=True)\n",
    "\n",
    "# start_point = 3000\n",
    "# plot_lenght = 4000\n",
    "\n",
    "# for i in range(data.shape[1]):\n",
    "#     ax[i].plot(range(plot_lenght),data[start_point:start_point+plot_lenght,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split data\n",
    "- test_size: 0.1\n",
    "- 10% of data is reserved for the real test --> X_test, y_test\n",
    "- 90% will be again divided into (train,test,val) --> X_model, y_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Reserve some data for REAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_model, X_test, y_model, y_test = train_test_split( X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_model:  (135, 16, 49)\n",
      "Shape of X_test:  (15, 16, 49)\n",
      "Shape of y_model:  (135,)\n",
      "Shape of y_test:  (15,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_model: \", X_model.shape)\n",
    "print(\"Shape of X_test: \",X_test.shape)\n",
    "print(\"Shape of y_model: \",y_model.shape)\n",
    "print(\"Shape of y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10 can be thought of as totally new eeg records and will be used as the real evaluation of our model.\n",
    "- For X : Chunking eeg to lengh of 10 data point in each stimuli's eeg\n",
    "- For y(lebels) : Filled the lebels in y because we chunk X ( 1 stimuli into 6 chunk). We have 500 labels before but now we need 500 x 6 = 3000 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def chunk_data(data, size):\n",
    "    data_keep = data.shape[2] - (data.shape[2]%size)\n",
    "    #print(f'{data.shape}')\n",
    "    data = data[:,:,:data_keep]\n",
    "    #print(f'{data.shape}')\n",
    "    #print(data[0,0,:20])\n",
    "    data = data.reshape(-1,data.shape[1],data.shape[2]//size,size)\n",
    "    #print(f'{data.shape}')\n",
    "    #print(data[0,0,:2,:])\n",
    "    data = np.transpose(data, (0, 2, 1, 3)  )\n",
    "    #print(f'{data.shape}')\n",
    "    #print(data[0,:2,0,:])\n",
    "    return data\n",
    "\n",
    "def filled_y(y, chunk_num):\n",
    "    yy = np.array([[i] *chunk_num for i in  y ]).ravel()\n",
    "    return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== X ==================\n",
      "Oringinal X shape (135, 16, 49)\n",
      "Chunked X : (135, 4, 16, 10)\n",
      "Reshape X to : (540, 16, 10)\n",
      "=================== y ==================\n",
      "Shape of y : (135,)\n",
      "(2430,)\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[2 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1 0 0 0 0 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 1 1 1 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 2 2 2 2 2 2\n",
      " 2 2 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 2 2 2 2 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 2 2 2 2 1 1 1 1 0 0 0 0 2 2 2 2 0 0 0 0 2 2 2 2 1 1 1 1 2 2\n",
      " 2 2 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 1 1 1 1 2\n",
      " 2 2 2 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 1 1 1 1 2 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 2 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2 2 2 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 2 2 2 2 0 0 0 0 2 2 2 2 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 0 0 0 0]\n",
      "Shape of new y : (2430,)\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 10 \n",
    "\n",
    "print('=================== X ==================')\n",
    "print(f'Oringinal X shape {X_model.shape}')\n",
    "X = chunk_data(X_model, chunk_size)\n",
    "print(f'Chunked X : {X.shape}') # (#stim, #chunks, #electrodes, #datapoint per chunk)\n",
    "chunk_per_stim = X.shape[1]\n",
    "X = X.reshape(-1,16,chunk_size)\n",
    "print(f'Reshape X to : {X.shape}')\n",
    "print('=================== y ==================')\n",
    "print(f'Shape of y : {y_model.shape}')\n",
    "\n",
    "y_new = np.zeros(2430) #100 labels, 62 chunks per label\n",
    "print(y_new.shape)\n",
    "size = 10\n",
    "for i,marker in enumerate(y_model):\n",
    "#     print(marker)\n",
    "    y_new[i*size:(i+1)*size] = y_model[i]\n",
    "y = y_new\n",
    "print(y)\n",
    "# print(y_new)\n",
    "y_filled = filled_y(y_model, chunk_per_stim)\n",
    "print(y_filled)\n",
    "print(f'Shape of new y : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 0 2 1 2 2 2 1 0 2 0 0 1 0 2 2 0 2 0 0 1 2 1 1 2 1 1 0 1 2 0 1 0 0\n",
      " 0 0 2 1 1 1 2 0 0 0 1 2 1 0 2 0 2 1 2 0 0 2 2 0 1 2 2 0 0 1 2 2 2 1 0 1 1\n",
      " 1 2 0 2 2 0 2 2 1 2 2 0 2 2 0 1 0 1 1 2 0 0 0 2 1 1 1 1 0 1 2 1 2 1 0 0 1\n",
      " 2 1 0 0 0 0 1 2 1 1 1 1 0 2 0 2 1 2 2 2 1 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Expected Input Shape: (batch, seq_len, channels)\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=bidirectional, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * num_layers, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        #*2 because it's bidirectional\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0)) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return\n",
    "\n",
    "class Conv1D_LSTM(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, seq_len, channels)\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout):\n",
    "        super(Conv1D_LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_1d = nn.Sequential(nn.Conv1d(input_dim, input_dim, [1,1]),nn.Dropout(dropout))\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=bidirectional, \n",
    "                           dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * num_layers, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Creating learnable preprocessing using conv1d\n",
    "        # conv1d expects (batch, channels, seq_len)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(1,3,0,2)   \n",
    "        x = self.conv_1d(x)\n",
    "        x = x.squeeze(2).permute(0,2,1)\n",
    "        \n",
    "        # Set initial hidden and cell states\n",
    "        #*2 because it's bidirectional\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach())) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training process\n",
    "\n",
    "We set `model.train()` so dropout is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "\n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        predicteds.append(predicted)\n",
    "        trues.append(labels)        \n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc,predicteds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels.long())\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            clear_output(wait=True)\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted) \n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)            \n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)            \n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Actual Training for Feature Extraction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Define model parameters\n",
    "- Count model parameters\n",
    "- optimizer\n",
    "- loss function\n",
    "- GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create the model from class\n",
    "# model_EEGEncoder = EEGEncoder()\n",
    "# model_EEGEncoder = model_EEGEncoder.float() #define precision as float to reduce running time\n",
    "# models = [model_EEGEncoder]\n",
    "\n",
    "\n",
    "# #Count the parameters for writing papers\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# for model in models:\n",
    "#     print(f'The model {type(model).__name__} has {count_parameters(model):,} trainable parameters')# Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Prepare X and y in correct shape\n",
    "\n",
    "- For X, pytorch (if set batch_first) LSTM requires to be (batch, seq_len, features).  Thus, for us, it should be (100, 75, 16).\n",
    "- For y, nothing is special\n",
    "- So let's convert our numpy to pytorch, and then reshape using view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of torch_X:  torch.Size([540, 16, 10])\n",
      "Shape of torch_y:  torch.Size([2430])\n"
     ]
    }
   ],
   "source": [
    "torch_X = torch.from_numpy(X)\n",
    "torch_y = torch.from_numpy(y)\n",
    "\n",
    "print(\"Shape of torch_X: \",torch_X.shape)\n",
    "print(\"Shape of torch_y: \",torch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X:  torch.Size([540, 16, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Original X: \", torch_X.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN requires the input shape as (batch, channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted X to  torch.Size([540, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch_X_reshaped = torch_X.reshape(torch_X.shape[0],torch_X.shape[1],1,torch_X.shape[2])\n",
    "torch_X_reshaped = torch_X.reshape(torch_X.shape[0], torch_X.shape[2], torch_X.shape[1])\n",
    "print(\"Converted X to \", torch_X_reshaped.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Split test train set, and load them into a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6dc7c813d600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_X_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Train test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define dataset\n",
    "ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "#Train test split\n",
    "train_size = int(torch_X_reshaped.size()[0] * 0.7)\n",
    "valid_size = int(torch_X_reshaped.size()[0] * 0.2)\n",
    "test_size  = torch_X_reshaped.size()[0] - train_size - valid_size\n",
    "\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size])\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128 #keeping it binary so it fits GPU\n",
    "#Train set loader\n",
    "train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "#Validation set loader\n",
    "valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "#Test set loader\n",
    "test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=test_size, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "bidirectional = True\n",
    "dropout = 0.65\n",
    "\n",
    "#CONV1D + LSTM\n",
    "model_conv1d_lstm = Conv1D_LSTM(input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout)\n",
    "model_conv1d_lstm = model_conv1d_lstm.float() #define precision as float to reduce running time\n",
    "\n",
    "models = [model_conv1d_lstm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "train_losses    = []\n",
    "valid_losses    = []\n",
    "\n",
    "learning_rate = 0.0001\n",
    "N_EPOCHS      = 5000          ## best is 10k\n",
    "criterion     = nn.NLLLoss()\n",
    "\n",
    "for model in models:\n",
    "    model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "optimizer     = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "train_predicted_labels = []\n",
    "valid_predicted_labels = []\n",
    "\n",
    "train_true_labels = []\n",
    "valid_true_labels = []\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Training {type(model).__name__}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label = evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc); train_predicted_labels.append(train_pred_label); train_true_labels.append(train_true_label); \n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc); valid_predicted_labels.append(valid_pred_label); valid_true_labels.append(valid_true_label); \n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)            \n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            print(\"Model:{} saved.\".format(type(model).__name__))\n",
    "            torch.save(model.state_dict(),\"../model/feature_extraction/round2/{par}/EEG_ENCODER.pt.tar\".format(par=par))\n",
    "            best_model_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.is_debug = False\n",
    "# iteration = 0\n",
    "\n",
    "# for i, model in enumerate(models):\n",
    "#     print(f\"Training {type(model).__name__}\")\n",
    "    \n",
    "#     start_time = time.time()\n",
    "\n",
    "#     for epoch in range(N_EPOCHS):\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         train_loss, train_acc, train_predicted    = train(model, train_iterator, optimizer, criterion)\n",
    "#         valid_loss, valid_acc, valid_predicted, _ = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "#         train_losses.append(train_loss)\n",
    "#         valid_losses.append(valid_loss)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "\n",
    "#         epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "#         iteration     += 1\n",
    "        \n",
    "#         if (epoch+1) % 50 == 0:\n",
    "#             clear_output(wait=True)\n",
    "#             print(f'Epoch: {epoch+1:02}/{N_EPOCHS}  |',end='')\n",
    "#             print(f'\\tTrain Loss: {train_loss:.5f}  | Train Acc: {train_acc:.2f}%  |', end='')\n",
    "#             print(f'\\t Val. Loss: {valid_loss:.5f}  | Val. Acc: {valid_acc:.2f}%')\n",
    "#             do_plot(train_losses, valid_losses)\n",
    "          \n",
    "\n",
    "#         if valid_loss < best_valid_loss:\n",
    "#             best_valid_loss = valid_loss\n",
    "#             print(\"Model:{} saved.\".format(type(model).__name__))\n",
    "#             torch.save(model.state_dict(), \"../model/feature_extraction/round2/{par}/EEG_ENCODER.pt.tar\".format(par=par))\n",
    "#             best_model_index = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluation (Test model)\n",
    "using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_to_list(_tmp):\n",
    "    from functools import reduce\n",
    "    import operator\n",
    "\n",
    "    xx     = [ i.cpu().detach().numpy().ravel().tolist() for i in _tmp]\n",
    "    xx     = reduce(operator.concat, xx)\n",
    "    return xx\n",
    "\n",
    "\n",
    "\n",
    "models[best_model_index].load_state_dict(torch.load('../model/feature_extraction/round2/{par}/EEG_ENCODER.pt.tar'.format(par=par)))\n",
    "\n",
    "\n",
    "\n",
    "# test_loss = evaluate(models[best_model_index], test_iterator, criterion)\n",
    "# print(f'Test Loss: {test_loss}') # | Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "test_loss, test_acc , predicted, actual_labels = evaluate(models[best_model_index], test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}%')\n",
    "print(\"---------------\")\n",
    "print(\" (Actual y , Predicted y)\")\n",
    "\n",
    "y_test     = squeeze_to_list(actual_labels)\n",
    "y_hat_test = squeeze_to_list(predicted)\n",
    "\n",
    "out = zip(y_test, y_hat_test)\n",
    "\n",
    "print(list(out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save features extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoder_best_model = models[best_model_index].load_state_dict(torch.load(f'save/{type(model).__name__}{i}.pth.tar'))\n",
    "# torch.save(encoder_best_model, 'save/7.1_encoder_best_model.pth.tar')\n",
    "\n",
    "\n",
    "### save Encoder network\n",
    "# torch.save(model_EEGEncoder, 'save/model_EEGEncoder_network_5s.pt.tar')\n",
    "# torch.save(test_iterator,'save/eeg_X_test_5s.pt.tar')\n",
    "\n",
    "\n",
    "# save extracted features\n",
    "eeg_encode = model_EEGEncoder.get_latent(torch_X_reshaped.to(device).float())\n",
    "eeg_extracted_features = eeg_encode.detach().cpu().numpy()\n",
    "np.save('../data/extracted_features/round2/{par}/{file}{task}_X'.format(par=par,file=file, task=task), eeg_extracted_features )\n",
    "np.save('../data/extracted_features/round2/{par}/{file}{task}_y'.format(par=par,file=file, task=task),y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
