{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acting-citizen",
   "metadata": {},
   "source": [
    "## 03 Epoching\n",
    "\n",
    "Epoching is a process of extracting only the relevant EEG data when the event happens.  Here we shall extract -0.1 seconds before the event starts until 0.5 seconds after the event starts.  Here we choose 0.5 seconds because we knew that our stimuli stay on for 0.5 seconds after the event starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "constitutional-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "from mne import Epochs, find_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-shepherd",
   "metadata": {},
   "source": [
    "### 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "animal-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    \n",
    "    #reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "    #                       grad=4000e-13,    # 4000 fT/cm\n",
    "    #                       eeg=100e-6,       # 150 μV\n",
    "    #                       eog=250e-6)       # 250 μV\n",
    "\n",
    "    reject_criteria = dict(eeg=100e-6)  #most voltage in this range is not brain components\n",
    "\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "conceptual-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 events found\n",
      "Event IDs: [1 2 3 4 5 6]\n",
      "sample drop %:  0.0\n"
     ]
    }
   ],
   "source": [
    "#this one requires expertise to specify the right tmin, tmax\n",
    "event_id = {'0': 1, '1' : 2, '2': 3, '3':4, '4':5, '5':6} #, '6':7, '7':8, '8':9, '9':10}\n",
    "tmin = 0 #0\n",
    "tmax = 5 #0.5 seconds\n",
    "picks= eeg_channels\n",
    "epochs = getEpochs(raw, event_id, tmin, tmax, picks)\n",
    "#print(epochs.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-civilization",
   "metadata": {},
   "source": [
    "Let's get our X and y in numpy form. Here X should have shape of (batch, channels, and samples) and y should have shape of (batch, ).   For the order of dimensions, we shall worry later on, depending on what deep learning libraries we use.\n",
    "\n",
    "For calculate of samples, since we get 0.5 seconds after 0.1 seconds before, and our sampling rate is 125, thus the total sample is 0.6 * 125 = 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "automated-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 16, 626)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "X = epochs.get_data()\n",
    "y = epochs.events[:, -1]\n",
    "#change to 0-9 \n",
    "y = y - 1\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "clear-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Plot\n",
    "# data = X.reshape(-1,16)\n",
    "# print(data.shape)\n",
    "# fig, ax = plt.subplots(16,1,figsize=(20,20),sharex=True)\n",
    "\n",
    "# for i in range(data.shape[1]):\n",
    "#     ax[i].plot(range(data.shape[0]),data[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "settled-interface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 16, 620)\n"
     ]
    }
   ],
   "source": [
    "# simply to get a nicer number\n",
    "X = X[:,:,:620]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-puppy",
   "metadata": {},
   "source": [
    "### Just checking reshape methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "tight-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.966172811559323e-06\n",
      "[ 7.96617281e-06  7.30075798e-06  2.31592821e-06  2.18310596e-06\n",
      "  8.75804369e-06  8.62963027e-06  1.39271303e-06  4.72741547e-07\n",
      "  2.74695240e-06 -2.37969071e-06]\n"
     ]
    }
   ],
   "source": [
    "print(X[0,0,0])\n",
    "print(X[0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "traditional-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 16, 62, 10)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(-1,16,62,10)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "agricultural-prior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.966172811559323e-06\n",
      "[ 7.96617281e-06  7.30075798e-06  2.31592821e-06  2.18310596e-06\n",
      "  8.75804369e-06  8.62963027e-06  1.39271303e-06  4.72741547e-07\n",
      "  2.74695240e-06 -2.37969071e-06]\n"
     ]
    }
   ],
   "source": [
    "print(X[0,0,0,0])\n",
    "print(X[0,0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "vital-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 62, 16, 10)\n",
      "7.966172811559323e-06\n",
      "[ 7.96617281e-06  7.30075798e-06  2.31592821e-06  2.18310596e-06\n",
      "  8.75804369e-06  8.62963027e-06  1.39271303e-06  4.72741547e-07\n",
      "  2.74695240e-06 -2.37969071e-06]\n"
     ]
    }
   ],
   "source": [
    "X = np.transpose(X,(0,2,1,3))\n",
    "print(X.shape)\n",
    "print(X[0,0,0,0])\n",
    "print(X[0,0,0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-communications",
   "metadata": {},
   "source": [
    "### 4. Make y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "progressive-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6200,)\n"
     ]
    }
   ],
   "source": [
    "y_new = np.zeros(6200) #100 labels, 62 chunks per label\n",
    "print(y_new.shape)\n",
    "size =62\n",
    "for i,marker in enumerate(y):\n",
    "    y_new[i*size:(i+1)*size] = y[i]\n",
    "# print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "metallic-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6200,)\n",
      "(100, 62)\n"
     ]
    }
   ],
   "source": [
    "print(y_new.shape)\n",
    "y_new = y_new.reshape(100,62)\n",
    "print(y_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-scenario",
   "metadata": {},
   "source": [
    "### Check shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "victorian-spencer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 62, 16, 10)\n",
      "(100, 62)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-vancouver",
   "metadata": {},
   "source": [
    "### 5. Preprocess like Zhang using minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "recent-location",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4464000 into shape (6200,160)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-4b2d594b6bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <<<< like Zhang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4464000 into shape (6200,160)"
     ]
    }
   ],
   "source": [
    "X = X.reshape(6200, 160) # <<<< like Zhang\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.minmax_scale(X, axis=1)\n",
    "X = X * 2 - 1\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(100,62,16,1,10)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-prairie",
   "metadata": {},
   "source": [
    "### 6. Take out some data for the REAL test later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-differential",
   "metadata": {},
   "source": [
    "#### 6.1 For the real test later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_model, X_test, y_model, y_test = train_test_split( X, y_new, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90 will be fed in to the model (divide to train, test, val).\n",
    "# 10 can be thought of as totally new eeg records and will be used as the real evaluation of our model.\n",
    "print(X_model.shape)\n",
    "print(X_test.shape)\n",
    "print(y_model.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-rings",
   "metadata": {},
   "source": [
    "#### 6.2 Chunking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = X_model.reshape(-1,16,1,10)\n",
    "y_model = y_model.reshape(-1)\n",
    "X_test = X_test.reshape(-1,16,1,10)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_model.shape)\n",
    "print(y_model.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-translator",
   "metadata": {},
   "source": [
    "### 7. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, seq_len, channels)\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=bidirectional, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * num_layers, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        #*2 because it's bidirectional\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0)) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D_LSTM(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, seq_len, channels)\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout):\n",
    "        super(Conv1D_LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_1d = nn.Sequential(nn.Conv1d(input_dim, input_dim, [1,1]),nn.Dropout(dropout))\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=bidirectional, \n",
    "                           dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * num_layers, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Creating learnable preprocessing using conv1d\n",
    "        # conv1d expects (batch, channels, seq_len)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(1,3,0,2)   \n",
    "        x = self.conv_1d(x)\n",
    "        x = x.squeeze(2).permute(0,2,1)\n",
    "        \n",
    "        # Set initial hidden and cell states\n",
    "        #*2 because it's bidirectional\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(device).float()\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach())) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-bachelor",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "bidirectional = True\n",
    "dropout = 0.65\n",
    "\n",
    "#LSTM\n",
    "model_lstm = LSTM(input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout)\n",
    "model_lstm = model_lstm.float() #define precision as float to reduce running time\n",
    "\n",
    "#CONV1D + LSTM\n",
    "model_conv1d_lstm = Conv1D_LSTM(input_dim, hidden_dim, num_layers, num_classes, bidirectional, dropout)\n",
    "model_conv1d_lstm = model_conv1d_lstm.float() #define precision as float to reduce running time\n",
    "\n",
    "models = [model_conv1d_lstm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-anniversary",
   "metadata": {},
   "source": [
    "Count the parameters for writing papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "for model in models:\n",
    "    print(f'The model {type(model).__name__} has {count_parameters(model):,} trainable parameters')# Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-amount",
   "metadata": {},
   "source": [
    "### 8. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-series",
   "metadata": {},
   "source": [
    "Define optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-treaty",
   "metadata": {},
   "source": [
    "Put them into GPU if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\"\n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-split",
   "metadata": {},
   "source": [
    "Prepare X and y in correct shape\n",
    "\n",
    "For X, pytorch (if set batch_first) LSTM requires to be (batch, seq_len, features).  Thus, for us, it should be (100, 75, 16).\n",
    "\n",
    "For y, nothing is special\n",
    "\n",
    "So let's convert our numpy to pytorch, and then reshape using view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_X = torch.from_numpy(X_model)\n",
    "torch_y = torch.from_numpy(y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original X: \", torch_X.size())\n",
    "# Expected Input Shape: (batch, seq_len, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_X_reshaped = torch_X.reshape(torch_X.shape[0], torch_X.shape[3], torch_X.shape[1])\n",
    "# torch_X_reshaped = torch_X.reshape(torch_X.shape[0],torch_X.shape[1],torch_X.shape[4],torch_X.shape[2])\n",
    "print(\"Converted X: \", torch_X_reshaped.size())\n",
    "print(\"y: \", torch_y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-interference",
   "metadata": {},
   "source": [
    "Split test train set, and load them into a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define dataset\n",
    "ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "#Train test split\n",
    "train_size = int(torch_X_reshaped.size()[0] * 0.7)+1 # +1 is needed here due to round-up round-down problem\n",
    "valid_size = int(torch_X_reshaped.size()[0] * 0.2)\n",
    "test_size = int(torch_X_reshaped.size()[0] * 0.1)\n",
    "print(train_size,valid_size,test_size)\n",
    "\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size]) \n",
    "\n",
    "BATCH_SIZE = 640 #keeping it binary so it fits GPU\n",
    "\n",
    "#Train set loader\n",
    "train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "#Validation set loader\n",
    "valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "#Test set loader\n",
    "test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-racing",
   "metadata": {},
   "source": [
    "Define the training process\n",
    "\n",
    "We set `model.train()` so dropout is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "\n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        predicteds.append(predicted)\n",
    "        trues.append(labels)        \n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc,predicteds, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-directive",
   "metadata": {},
   "source": [
    "We define a function for testing our model. We wet `model.eval()` since we do not use dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels.long())\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            clear_output(wait=True)\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted) \n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)            \n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)            \n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-husband",
   "metadata": {},
   "source": [
    "We will also define a time function useful for calculating time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-harassment",
   "metadata": {},
   "source": [
    "Finally, we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "train_predicted_labels = []\n",
    "valid_predicted_labels = []\n",
    "\n",
    "train_true_labels = []\n",
    "valid_true_labels = []\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Training {type(model).__name__}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label = evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc); train_predicted_labels.append(train_pred_label); train_true_labels.append(train_true_label); \n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc); valid_predicted_labels.append(valid_pred_label); valid_true_labels.append(valid_true_label); \n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)            \n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            print(\"Model:{} saved.\".format(type(model).__name__))\n",
    "            torch.save(model.state_dict(), f'../notebooks_beau/{type(model).__name__}{i}.pth.tar')\n",
    "            best_model_index = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-adaptation",
   "metadata": {},
   "source": [
    "### 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_model_index].load_state_dict(torch.load(f'../notebooks_beau/{type(model).__name__}{i}.pth.tar'))\n",
    "\n",
    "test_loss, test_acc, test_pred_label, test_true_label  = evaluate(models[best_model_index], test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}%')\n",
    "# print(test_pred_label)\n",
    "# print(test_true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,sharex=True,figsize=(10,10))\n",
    "ax[0].plot(np.arange(N_EPOCHS),train_losses,label = \"train loss\")\n",
    "ax[0].plot(np.arange(N_EPOCHS),valid_losses, label = \"valid loss\")\n",
    "ax[1].plot(np.arange(N_EPOCHS),train_accs,label = \"train acc\")\n",
    "ax[1].plot(np.arange(N_EPOCHS),valid_accs,label = \"valid acc\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.03)\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].grid(True)\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-reporter",
   "metadata": {},
   "source": [
    "As shown above, the model performs well on both train, validation as well as test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-straight",
   "metadata": {},
   "source": [
    "### 10. REAL EVALUATION!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-partnership",
   "metadata": {},
   "source": [
    "Here is the real test, we are using X_test and y_test that i separated from the very begining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_X_test = torch.from_numpy(X_test)\n",
    "torch_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original X: \", torch_X_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_X_reshaped_test = torch_X_test.reshape(torch_X_test.shape[0], torch_X_test.shape[3], torch_X_test.shape[1])\n",
    "# torch_X_reshaped = torch_X.reshape(torch_X.shape[0],torch_X.shape[1],torch_X.shape[4],torch_X.shape[2])\n",
    "print(\"Converted X: \", torch_X_reshaped_test.size())\n",
    "print(\"y: \", torch_y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = TensorDataset(torch_X_reshaped_test, torch_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set loader\n",
    "test_iterator_test = torch.utils.data.DataLoader(dataset= ds_test, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_model_index].load_state_dict(torch.load(f'../notebooks_beau/{type(model).__name__}{i}.pth.tar'))\n",
    "\n",
    "test_loss_test, test_acc_test, test_pred_label_test, test_true_label_test  = evaluate(models[best_model_index], test_iterator_test, criterion)\n",
    "print(f'Test Loss: {test_loss_test:.3f} | Test Acc: {test_acc_test:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-wallet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-temple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-veteran",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
